# âš½ Football Performance Analysis Pipeline (PySpark)

## ğŸ“– Contexte du projet

Les donnÃ©es footballistiques reprÃ©sentent une source prÃ©cieuse pour analyser les performances des Ã©quipes, identifier les tendances saisonniÃ¨res et soutenir la prise de dÃ©cision dans le sport.  
Ce projet a pour objectif de construire un **pipeline PySpark complet** permettant dâ€™analyser la performance des Ã©quipes **saison par saison**, de calculer des **indicateurs clÃ©s de performance (KPI)**, de **classer les Ã©quipes**, et de **stocker les rÃ©sultats au format Parquet partitionnÃ©**.

---

## ğŸ¯ Objectifs

- Charger et prÃ©parer les donnÃ©es de matchs de football.
- Calculer des statistiques avancÃ©es par Ã©quipe et par saison.
- Identifier les **champions de chaque saison**.
- Sauvegarder les rÃ©sultats sous format **Parquet partitionnÃ© par saison**.
- Visualiser les performances des Ã©quipes gagnantes.
- (Bonus) IntÃ©grer le pipeline dans **Databricks** et crÃ©er un **dashboard Power BI**.

---

## ğŸ‘¥ User Stories

| RÃ´le | Besoin | RÃ©sultat attendu |
|------|---------|------------------|
| **Analyste** | Visualiser un tableau clair des performances par Ã©quipe et par saison. | Table des KPI par saison. |
| **Supporter** | ConnaÃ®tre les champions de chaque saison. | Tableau ou graphique des Ã©quipes championnes. |
| **Manager sportif** | Disposer dâ€™indicateurs (% victoires, buts marquÃ©s, goal diff) pour orienter la stratÃ©gie. | Dashboard Power BI ou graphiques. |

---

## âš™ï¸ Architecture du pipeline

### Ã‰tapes principales :

1. **Chargement et prÃ©paration des donnÃ©es**
   - Import du fichier CSV dans un DataFrame PySpark.
   - Nettoyage et renommage des colonnes selon `footballcolumnsdocumentation.pdf`.

2. **CrÃ©ation de colonnes supplÃ©mentaires**
   - Colonnes indicatrices :  
     `HomeTeamWin`, `AwayTeamWin`, `GameTie`.

3. **Filtrage des donnÃ©es**
   - Conservation uniquement de la **Bundesliga (Div = D1)**.  
   - PÃ©riode : **2000 Ã  2015**.

4. **AgrÃ©gations**
   - `df_home_matches` : statistiques Ã  domicile.  
   - `df_away_matches` : statistiques Ã  lâ€™extÃ©rieur.  
   - Jointure â†’ `df_merged`.

5. **Calcul des KPI**
   - Colonnes totales : `GoalsScored`, `GoalsAgainst`, `Win`, `Loss`, `Tie`.  
   - Colonnes avancÃ©es :  
     `GoalDifferentials`, `WinPercentage`, `GoalsPerGame`, `GoalsAgainstPerGame`.

6. **Classement des Ã©quipes**
   - Utilisation des **Window Functions** pour classer les Ã©quipes selon :
     - `WinPercentage`
     - `GoalDifferentials`
   - Extraction du champion : `TeamPosition = 1`.

7. **Sauvegarde optimisÃ©e**
   - `football_stats_partitioned` : toutes les Ã©quipes, partitionnÃ© par saison.  
   - `football_top_teams` : champions uniquement.

8. **Visualisation (Pandas / Matplotlib / Power BI)**
   - Graphiques :
     - % de victoires des champions.
     - Nombre de buts marquÃ©s.
     - GoalDifferentials par saison.

---

## ğŸ§© Structure du projet

```
football-pyspark-pipeline/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ football_analysis_pyspark.ipynb # Notebook Google Colab ou Databricks
â”‚
â”œâ”€â”€ src/
â”‚ â””â”€â”€ pipeline_utils.py # Fonctions PySpark (agrÃ©gations, KPIs, ranking)
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ football_matches.csv # DonnÃ©es sources
â”‚ â”œâ”€â”€ football_stats_partitioned/ # Parquet partitionnÃ© par saison
â”‚ â””â”€â”€ football_top_teams/ # Champions
â”‚
â”œâ”€â”€ visuals/
â”‚ â”œâ”€â”€ win_percentage_champions.png
â”‚ â”œâ”€â”€ goals_scored_champions.png
â”‚ â””â”€â”€ goal_differentials_champions.png
â”‚
â”œâ”€â”€ footballcolumnsdocumentation.pdf # Documentation colonnes
â””â”€â”€ README.md

```

---

## ğŸ“Š Exemples de KPI calculÃ©s

| KPI | Description | Formule |
|-----|--------------|----------|
| **WinPercentage** | Pourcentage de victoires | `Wins / (Wins + Losses + Ties)` |
| **GoalsPerGame** | Moyenne de buts marquÃ©s par match | `GoalsScored / GamesPlayed` |
| **GoalsAgainstPerGame** | Moyenne de buts encaissÃ©s par match | `GoalsAgainst / GamesPlayed` |
| **GoalDifferentials** | DiffÃ©rence de buts | `GoalsScored - GoalsAgainst` |

---

## ğŸª¶ Technologies utilisÃ©es

| CatÃ©gorie | Outils |
|------------|--------|
| **Langage principal** | Python 3.10+ |
| **Traitement distribuÃ©** | Apache Spark / PySpark |
| **Stockage optimisÃ©** | Parquet partitionnÃ© |
| **Exploration / Visualisation** | Pandas, Matplotlib, Power BI |
| **Environnement dâ€™exÃ©cution** | Google Colab, Databricks Community Edition |
| **Gestion de version** | GitHub |

---

## ğŸ§  Concepts techniques clÃ©s

- **PySpark DataFrame API** : pour les transformations distribuÃ©es.
- **GroupBy & Aggregations** : statistiques par Ã©quipe et saison.
- **Window Functions** : classement par saison.
- **Parquet partitionnÃ©** : stockage optimisÃ© pour la lecture sÃ©lective.
- **Matplotlib / Power BI** : visualisation de la performance.

---

## ğŸ§± Commandes utiles

### â–¶ï¸ Lancer le pipeline (dans un notebook Colab)
```python
!pip install pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("FootballAnalysis").getOrCreate()
df = spark.read.csv("/content/football_matches.csv", header=True, inferSchema=True)
```
### ğŸ’¾ Sauvegarde en Parquet partitionnÃ©
```python
df_final.write.mode("overwrite").partitionBy("Season").parquet("/content/football_stats_partitioned")
```

### ğŸ“ˆ Lecture du Parquet
```python
df = spark.read.parquet("/content/football_stats_partitioned")
df.printSchema()
```
# âš½ Football Data Engineering avec PySpark, Databricks et Power BI

## ğŸ† RÃ©sultats attendus

### ğŸ“‚ Datasets gÃ©nÃ©rÃ©s

- **`football_stats_partitioned`** : contient toutes les Ã©quipes, partitionnÃ© par **saison**.  
- **`football_top_teams`** : contient uniquement les **champions** de chaque saison.

### ğŸ“Š Visualisations attendues

1. **Pourcentage de victoires des champions**
2. **Nombre de buts marquÃ©s par saison**
3. **GoalDifferentials (diffÃ©rence de buts)** par saison

---

## Bonus : DÃ©ploiement Databricks et Power BI

### ğŸ’» Sur Databricks
- RecrÃ©er le pipeline dans un **notebook Databricks Community Edition (CE)**.  
- Comparer les **performances** entre **Google Colab** et **Databricks**.  
- Utiliser la commande :
  ```python
  display(df)
  ```
### ğŸ“ˆ Sur Power BI

- Importer les fichiers **`.parquet`** gÃ©nÃ©rÃ©s depuis le dossier : ``/data``

- CrÃ©er un **tableau de bord interactif** comprenant :
- Pourcentage de victoires (**%Win**)
- Nombre de buts marquÃ©s (**Goals**)
- DiffÃ©rence de buts (**GoalDiff**)

- Ajouter des **filtres dynamiques** :
- Par **saison**
- Par **Ã©quipe**

---

## ğŸ“š RÃ©fÃ©rences

- [Apache Spark â€” Documentation officielle](https://spark.apache.org/docs/latest/)
- [Databricks Community Edition](https://community.cloud.databricks.com/)
- [Power BI â€” Importer des fichiers Parquet](https://learn.microsoft.com/fr-fr/power-bi/connect-data/desktop-connect-parquet)
- [Football Data Source â€” Kaggle](https://www.kaggle.com/datasets)
- [Football Data Europe](https://www.football-data.co.uk/)

---

## ğŸ§‘â€ğŸ’» Auteur

**Salim Majide**  
ğŸ“ *IngÃ©nieur Big Data & Cloud Computing (ENSET Mohammedia)*  
ğŸ’¼ *Projet Data Engineering - PySpark*  
ğŸ“§ **Contact : [LinkedIn](https://www.linkedin.com/in/salim-majide-231319172)** 

---

## ğŸ“¦ Livrables

1. **Notebook Google Colab ou Databricks commentÃ©**  
2. **Datasets Parquet :**
``/data/football_stats_partitioned``
``/data/football_top_teams``
3. **Graphiques :** Win%, Goals, GoalDiff  
4. **Lien GitHub :** Notebook, Datasets Parquet, Visualisations, README

---

## ğŸ Conclusion

Ce projet illustre la **mise en Å“uvre complÃ¨te dâ€™un pipeline de donnÃ©es PySpark**,  
depuis la **prÃ©paration** jusquâ€™Ã  la **visualisation**, en appliquant les **bonnes pratiques dâ€™ingÃ©nierie de donnÃ©es**,  
ainsi que les principes dâ€™**optimisation des performances** et de **dÃ©ploiement sur Databricks et Power BI**.





